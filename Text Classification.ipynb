{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5979390b-fec4-4d77-a5c1-e6217bf23f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b29982-c334-4711-8b1e-c042fa6eff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\noran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\noran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\noran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\noran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bf93ee-457d-42f4-a558-5b2f4aaf8b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>cleaned_review_length</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>positive</td>\n",
       "      <td>i love this speaker and love can take it anywh...</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17336</th>\n",
       "      <td>positive</td>\n",
       "      <td>i use it in my house easy to connect and loud ...</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17337</th>\n",
       "      <td>positive</td>\n",
       "      <td>the bass is good and the battery is amazing mu...</td>\n",
       "      <td>41</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>positive</td>\n",
       "      <td>love it</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mono speaker</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiments                                     cleaned_review  \\\n",
       "0       positive  i wish would have gotten one earlier love it a...   \n",
       "1        neutral  i ve learned this lesson again open the packag...   \n",
       "2        neutral          it is so slow and lags find better option   \n",
       "3        neutral  roller ball stopped working within months of m...   \n",
       "4        neutral  i like the color and size but it few days out ...   \n",
       "...          ...                                                ...   \n",
       "17335   positive  i love this speaker and love can take it anywh...   \n",
       "17336   positive  i use it in my house easy to connect and loud ...   \n",
       "17337   positive  the bass is good and the battery is amazing mu...   \n",
       "17338   positive                                            love it   \n",
       "17339    neutral                                       mono speaker   \n",
       "\n",
       "       cleaned_review_length  review_score  \n",
       "0                         19           5.0  \n",
       "1                         88           1.0  \n",
       "2                          9           2.0  \n",
       "3                         12           1.0  \n",
       "4                         21           1.0  \n",
       "...                      ...           ...  \n",
       "17335                     30           5.0  \n",
       "17336                     13           4.0  \n",
       "17337                     41           5.0  \n",
       "17338                      2           5.0  \n",
       "17339                      2           5.0  \n",
       "\n",
       "[17340 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"amazon_reviews.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690fe0e9-1e2a-45aa-a2e5-18e7a82ff051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>positive</td>\n",
       "      <td>i love this speaker and love can take it anywh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17336</th>\n",
       "      <td>positive</td>\n",
       "      <td>i use it in my house easy to connect and loud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17337</th>\n",
       "      <td>positive</td>\n",
       "      <td>the bass is good and the battery is amazing mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>positive</td>\n",
       "      <td>love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mono speaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17340 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiments                                     cleaned_review\n",
       "0       positive  i wish would have gotten one earlier love it a...\n",
       "1        neutral  i ve learned this lesson again open the packag...\n",
       "2        neutral          it is so slow and lags find better option\n",
       "3        neutral  roller ball stopped working within months of m...\n",
       "4        neutral  i like the color and size but it few days out ...\n",
       "...          ...                                                ...\n",
       "17335   positive  i love this speaker and love can take it anywh...\n",
       "17336   positive  i use it in my house easy to connect and loud ...\n",
       "17337   positive  the bass is good and the battery is amazing mu...\n",
       "17338   positive                                            love it\n",
       "17339    neutral                                       mono speaker\n",
       "\n",
       "[17340 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['cleaned_review_length', 'review_score'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6858b818-d053-446b-8ab7-efde98eb0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments        0\n",
       "cleaned_review    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401c3fe5-ec3b-4c23-b46b-e6a9d4a9f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments\n",
       "positive    9503\n",
       "neutral     6300\n",
       "negative    1534\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop missing values\n",
    "data = data.dropna()\n",
    "data['sentiments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4323396-aa24-4421-bc8b-6187340f4177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words before filtering:\n",
      " {\"hadn't\", 'our', 'while', \"isn't\", 'each', 'will', 'didn', \"don't\", \"haven't\", 'they', 'don', 'there', 'but', 'we', \"you'd\", 'their', 'why', 'ain', 'doesn', \"mustn't\", \"weren't\", 'yourself', 'having', 'hers', 'about', 'against', 'its', 'yourselves', \"shouldn't\", 'ourselves', 'she', 'some', 'o', 'm', 'theirs', 'those', \"hasn't\", 'into', 'both', 'he', 'until', 'have', 'same', 'me', \"you've\", 'any', 'myself', 'more', 'be', 'how', 'should', 'what', 'such', 'very', 'ours', 'that', 'further', 've', 'in', 'wouldn', \"didn't\", \"doesn't\", 'can', 'y', 'of', \"wouldn't\", 'under', 'out', 'been', 'them', \"wasn't\", 'my', 'after', 'were', 'won', 'themselves', \"that'll\", 'mustn', 'do', 'just', 'i', 'when', 'and', 'at', 'who', 'now', 'him', 'being', 'has', \"you'll\", 'with', 'by', 'off', 'down', 'yours', 'was', 'wasn', 'is', 'during', 'aren', 'no', 'a', 's', 'shouldn', 'through', 'below', 'needn', 'his', 'than', 'an', 'above', 'isn', 'her', 'few', 'again', 'you', 'himself', 'did', 're', 'before', 'your', 'herself', 'over', 'or', 'other', 'haven', 'whom', 'which', 'up', 'as', 'once', 'am', 'on', \"it's\", \"shan't\", 'nor', 'so', 'if', \"should've\", 'couldn', 'not', \"she's\", 'most', \"mightn't\", 'here', 'then', 'shan', 'these', 'it', \"needn't\", 'are', \"couldn't\", 'between', 'hadn', 'hasn', 'for', 'too', 'own', 'where', 'ma', 'mightn', \"you're\", 'from', 'this', \"aren't\", 'itself', 'all', 'weren', \"won't\", 'll', 'the', 'to', 'had', 'only', 'doing', 'because', 'd', 'does', 't'} \n",
      "\n",
      "Stop words after filtering negations:\n",
      " {'our', 'while', 'each', 'will', 'didn', 'must', 'they', 'don', 'there', 'but', 'we', \"you'd\", 'their', 'why', 'ain', 'doesn', 'yourself', 'having', 'might', 'hers', 'about', 'against', 'its', 'yourselves', 'ourselves', 'she', 'some', 'o', 'm', 'theirs', 'those', 'into', 'both', 'he', 'until', 'have', 'would', 'same', 'me', \"you've\", 'any', 'myself', 'more', 'be', 'how', 'should', 'what', 'such', 'very', 'ours', 'that', 'further', 've', 'in', 'wouldn', 'can', 'y', 'of', 'under', 'out', 'been', 'need', 'them', 'my', 'after', 'were', 'won', 'themselves', \"that'll\", 'mustn', 'do', 'just', 'i', 'when', 'and', 'at', 'who', 'now', 'him', 'being', 'has', \"you'll\", 'with', 'by', 'off', 'down', 'yours', 'was', 'wasn', 'is', 'during', 'aren', 'a', 's', 'shouldn', 'could', 'through', 'below', 'needn', 'his', 'than', 'an', 'above', 'isn', 'her', 'few', 'again', 'you', 'himself', 'did', 're', 'before', 'your', 'herself', 'over', 'or', 'other', 'haven', 'whom', 'which', 'up', 'as', 'once', 'am', 'on', \"it's\", 'so', 'wo', 'if', \"should've\", 'couldn', \"she's\", 'most', 'here', 'then', 'shan', 'these', 'it', 'are', 'sha', 'between', 'hadn', 'hasn', 'for', 'too', 'own', 'where', 'ma', 'mightn', \"you're\", 'from', 'this', 'itself', 'all', 'weren', 'll', 'the', 'to', 'had', 'only', 'doing', 'because', 'd', 'does', 't'}\n"
     ]
    }
   ],
   "source": [
    "def remove_negated_stopwords(stop_words):\n",
    "    # Define negated stop words\n",
    "    negation = set([\"no\", \"not\", \"never\", \"none\", \"nobody\", \"nowhere\", \"nothing\", \"neither\", \"nor\", \"noone\"])\n",
    "\n",
    "\n",
    "\n",
    "    # Remove negated stop words\n",
    "    modified_stop_words = stop_words - negation\n",
    "    # print(modified_stop_words)\n",
    "\n",
    "    # regular expression to match words ending with \"n't\"\n",
    "    suffix_pattern = re.compile(r\"n't\")\n",
    "\n",
    "    for word in list(stop_words):\n",
    "        # If a word ends with \"n't\"\n",
    "        if suffix_pattern.search(word):\n",
    "            # Substitute the suffix with an empty string\n",
    "            main_word = re.sub(suffix_pattern, '', word)\n",
    "\n",
    "            #Remove the negated word from the modified stop words set\n",
    "            modified_stop_words.remove(word)\n",
    "\n",
    "            # Add the orginal word to the modified stop words set\n",
    "            modified_stop_words.add(main_word)\n",
    "\n",
    "    return modified_stop_words\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"Stop words before filtering:\\n\", stop_words , \"\\n\")\n",
    "\n",
    "modified_stop_words = remove_negated_stopwords(stop_words)\n",
    "print(\"Stop words after filtering negations:\\n\", modified_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb3c718-1c85-4b61-9041-2ade9b9dce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    #Convert to lowercase\n",
    "    data = data.lower()\n",
    "\n",
    "    doc = nlp(data)\n",
    "\n",
    "    #Tokenize data\n",
    "    tokens = nltk.word_tokenize(data)\n",
    "\n",
    "    #Remove stop words and punctuations\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    modified_stop_words = remove_negated_stopwords(stop_words)\n",
    "\n",
    "    filtered_tokens = [token for token in tokens if token.isalpha() and token not in modified_stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if token.is_alpha and token.text not in modified_stop_words]\n",
    "\n",
    "    # Convert tokens into text again (into single string)\n",
    "    preprocessed_data = ' '.join(lemmatized_tokens)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2bbba7f-be4d-432f-ac83-73084389060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show preprocessed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>wish get one early love make work laptop much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>learn lesson open package use product right aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>slow lag find well option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stop work within month minimal use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>like color size day return period not hold charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>positive</td>\n",
       "      <td>love speaker love take anywhere charge phone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17336</th>\n",
       "      <td>positive</td>\n",
       "      <td>use house easy connect loud clear music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17337</th>\n",
       "      <td>positive</td>\n",
       "      <td>bass good battery amazing much well charge thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>positive</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mono speaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17337 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiments                                     cleaned_review\n",
       "0       positive  wish get one early love make work laptop much ...\n",
       "1        neutral  learn lesson open package use product right aw...\n",
       "2        neutral                          slow lag find well option\n",
       "3        neutral  roller ball stop work within month minimal use...\n",
       "4        neutral  like color size day return period not hold charge\n",
       "...          ...                                                ...\n",
       "17335   positive  love speaker love take anywhere charge phone w...\n",
       "17336   positive            use house easy connect loud clear music\n",
       "17337   positive  bass good battery amazing much well charge thi...\n",
       "17338   positive                                               love\n",
       "17339    neutral                                       mono speaker\n",
       "\n",
       "[17337 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing to the text column\n",
    "data['cleaned_review'] = data['cleaned_review'].apply(data_preprocessing)\n",
    "\n",
    "print(\"Show preprocessed data:\")\n",
    "data\n",
    "# print(data['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f426b8-be85-47d2-87cd-c4ff60eb0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cleaned_review']\n",
    "Y = data['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b40039-d742-4051-aca5-ab12f491b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder (pos=>0 , Neu=>1, Neg=>2)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the column containing strings\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Word Embedding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "maxlen = max([len(seq) for seq in X_train_sequences + X_test_sequences])\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_sequences, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2dc9cea-c3e9-4585-9b22-9b04a0604cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def train_model(model_type, X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length=maxlen))\n",
    "\n",
    "    if model_type == 'SimpleRNN':\n",
    "        model.add(SimpleRNN(128, return_sequences=False))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(128, return_sequences=False))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Model summary\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "576aad68-22dc-476d-bf55-411c74259972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.6389 - loss: 0.7784 - val_accuracy: 0.8108 - val_loss: 0.5129\n",
      "Epoch 2/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 77ms/step - accuracy: 0.8237 - loss: 0.4699 - val_accuracy: 0.8209 - val_loss: 0.4755\n",
      "Epoch 3/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 71ms/step - accuracy: 0.8468 - loss: 0.4096 - val_accuracy: 0.8377 - val_loss: 0.4624\n",
      "Epoch 4/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - accuracy: 0.8886 - loss: 0.3198 - val_accuracy: 0.8449 - val_loss: 0.4414\n",
      "Epoch 5/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 70ms/step - accuracy: 0.9182 - loss: 0.2560 - val_accuracy: 0.8480 - val_loss: 0.4757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">316</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">861,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m316\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m861,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,684,939</span> (10.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,684,939\u001b[0m (10.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">894,979</span> (3.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m894,979\u001b[0m (3.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,789,960</span> (6.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,789,960\u001b[0m (6.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train SimpleRNN model\n",
    "simple_rnn_model = train_model('SimpleRNN', X_train_pad, y_train, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24db938a-15ae-4965-84f6-9bd480e6363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8501 - loss: 0.4564\n",
      "RNN Model Accuracy: 0.8480392098426819\n",
      "RNN Model rnn_loss: 0.47567227482795715\n"
     ]
    }
   ],
   "source": [
    "rnn_loss, rnn_accuracy = simple_rnn_model.evaluate(X_test_pad, y_test)\n",
    "\n",
    "print(f'RNN Model Accuracy: {rnn_accuracy}')\n",
    "print(f'RNN Model rnn_loss: {rnn_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32768d70-4b54-4e78-936c-e817ab946736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 204ms/step - accuracy: 0.6790 - loss: 0.7014 - val_accuracy: 0.8377 - val_loss: 0.4169\n",
      "Epoch 2/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 199ms/step - accuracy: 0.8755 - loss: 0.3401 - val_accuracy: 0.8622 - val_loss: 0.3743\n",
      "Epoch 3/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 206ms/step - accuracy: 0.9115 - loss: 0.2453 - val_accuracy: 0.8737 - val_loss: 0.3751\n",
      "Epoch 4/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 194ms/step - accuracy: 0.9263 - loss: 0.2138 - val_accuracy: 0.8685 - val_loss: 0.3893\n",
      "Epoch 5/5\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 173ms/step - accuracy: 0.9351 - loss: 0.1924 - val_accuracy: 0.8777 - val_loss: 0.4117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">316</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">861,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m316\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m861,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,981,003</span> (11.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,981,003\u001b[0m (11.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">993,667</span> (3.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m993,667\u001b[0m (3.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,987,336</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,987,336\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train LSTM model\n",
    "lstm_model = train_model('LSTM', X_train_pad, y_train, X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8695f8f-2f79-4470-b65d-bf49baae3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.8780 - loss: 0.4032\n",
      " lstm Model Accuracy: 0.8777393102645874\n",
      " lstm Model rnn_loss: 0.411745548248291\n"
     ]
    }
   ],
   "source": [
    "lstm_loss,  lstm_accuracy = lstm_model.evaluate(X_test_pad, y_test)\n",
    "\n",
    "print(f' lstm Model Accuracy: {lstm_accuracy}')\n",
    "print(f' lstm Model rnn_loss: {lstm_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cc7005d-0f3c-441a-92d4-fa61bab2b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Input Prediction\n",
    "def predict_review(review):\n",
    "    review_cleaned = data_preprocessing(review)\n",
    "    review_seq = tokenizer.texts_to_sequences([review_cleaned])\n",
    "    review_pad = pad_sequences(review_seq, maxlen=maxlen)\n",
    "    rnn_prediction = simple_rnn_model.predict(review_pad)\n",
    "    lstm_prediction = lstm_model.predict(review_pad)\n",
    "    return {\n",
    "        'Simple RNN': label_encoder.inverse_transform(np.argmax(rnn_prediction, axis=1))[0],\n",
    "        'LSTM': label_encoder.inverse_transform(np.argmax(lstm_prediction, axis=1))[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6501139-e7e1-471c-a021-6000f5396a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
      "Predicted class: {'Simple RNN': 'neutral', 'LSTM': 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "# Test user input prediction\n",
    "review = input()\n",
    "predicted_class = predict_review(review)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448b4f1-77e5-47c5-a5b2-3021d48b6edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
